# PUCP Cloud Orchestrator

Sistema completo de orquestaciÃ³n de nubes para la PUCP que permite gestionar slices de red con topologÃ­as predefinidas en infraestructuras hÃ­bridas (OpenStack + Linux Cluster).

## CaracterÃ­sticas Principales

### ğŸ” Sistema de AutenticaciÃ³n
- Login por usuario con JWT tokens
- GestiÃ³n de sesiones seguras
- Control de acceso por usuario

### ğŸŒ TopologÃ­as Predefinidas
- **Lineal**: Nodos conectados en serie (A â†’ B â†’ C â†’ D)
- **Malla**: Todos los nodos conectados entre sÃ­
- **Ãrbol**: Estructura jerÃ¡rquica en Ã¡rbol
- **Anillo**: Nodos conectados en cÃ­rculo
- **Bus**: Todos los nodos conectados a un bus central

### ğŸ“Š GestiÃ³n de Slices
- Editor visual de slices con drag & drop
- ConfiguraciÃ³n de capacidad de VMs (vCPUs, RAM, disco)
- Despliegue automÃ¡tico en OpenStack o Linux Cluster
- Monitoreo en tiempo real del estado de slices
- EliminaciÃ³n de slices con limpieza completa

### ğŸ’¾ GestiÃ³n de ImÃ¡genes
- Subida de imÃ¡genes de VMs (.qcow2, .vmdk, .img, .raw)
- ValidaciÃ³n automÃ¡tica de imÃ¡genes
- Soporte para imÃ¡genes pÃºblicas y privadas
- IntegraciÃ³n con Glance (OpenStack) y libvirt

### ğŸ“ˆ Monitoreo de Recursos
- Vista en tiempo real del consumo de recursos
- MÃ©tricas de CPU, RAM, disco y red
- GrÃ¡ficos interactivos con Chart.js
- Alertas de utilizaciÃ³n

### ğŸ–¥ï¸ Acceso a Consolas
- Consolas VNC para VMs OpenStack
- Consolas seriales para debugging
- Tokens temporales de acceso
- Credenciales automÃ¡ticas

## Arquitectura

### Componentes Principales
- **Web Application** (`web_app.py`): Interfaz web principal con Flask
- **OpenStack Service** (`microservicios/openstack_service/`): Microservicio para OpenStack
- **SSH Tunnel Manager** (`microservicios/ssh_tunnel_manager.py`): GestiÃ³n de tÃºneles SSH
- **Frontend**: HTML5, Bootstrap 5, jQuery, Chart.js

### Infraestructura Soportada
- **OpenStack**: Acceso remoto via SSH jumper/bastion
  - Jumper: ubuntu@10.20.12.187:5821 
  - Headnode: 192.168.202.1 (red interna)
  - Arquitectura: App Server â†’ Jumper â†’ Headnode
- **Linux Cluster**: GestiÃ³n local con libvirt/KVM
- **Base de Datos**: SQLite para persistencia

## InstalaciÃ³n

### Requisitos Previos
```bash
# Python 3.8+
python3 --version

# SSH client
ssh -V

# Dependencias Python
pip install flask flask-cors PyJWT sqlite3 requests paramiko
```

### ConfiguraciÃ³n SSH
1. Generar clave SSH si no existe:
```bash
ssh-keygen -t rsa -b 4096 -f ~/.ssh/id_rsa
```

2. Copiar clave al jumper/bastion:
```bash
ssh-copy-id -p 5821 ubuntu@10.20.12.187
```

3. Probar conexiÃ³n al jumper:
```bash
ssh -p 5821 ubuntu@10.20.12.187
```

4. Desde el jumper, verificar acceso al headnode:
```bash
# Dentro del jumper
ping 192.168.202.1
nc -z 192.168.202.1 5000  # Puerto Keystone OpenStack
```

5. Probar tÃºnel SSH completo (ejemplo):
```bash
ssh -NL 8080:192.168.202.1:80 ubuntu@10.20.12.187 -p 5821
# Esto abre tÃºnel del puerto local 8080 al puerto 80 del headnode
```

### ConfiguraciÃ³n de OpenStack
Editar `microservicios/edits/openstack_config_ssh.py`:
```python
SSH_CONFIG = {
    'jumper_host': '10.20.12.187',         # IP del jumper/bastion
    'jumper_port': 5821,                   # Puerto SSH del jumper
    'jumper_user': 'ubuntu',               # Usuario para el jumper
    'openstack_headnode': '192.168.202.1', # IP del headnode OpenStack
    'ssh_key_path': os.path.expanduser('~/.ssh/id_rsa'),
}

OPENSTACK_CONFIG = {
    'username': 'admin',
    'password': 'tu_password',
    'project_name': 'admin',
    # URLs serÃ¡n automÃ¡ticamente redirigidas a travÃ©s del tÃºnel
    # Ej: http://localhost:15000 -> 192.168.202.1:5000
}
```

## Uso

### Inicio RÃ¡pido
```bash
# Clonar o descargar el proyecto
cd cloud-2022

# Iniciar todos los servicios
python3 start_pucp_cloud.py
```

### Inicio Manual
```bash
# Terminal 1: OpenStack Service
python3 microservicios/openstack_service/openstack_service.py

# Terminal 2: Web Application
python3 web_app.py
```

### URLs de Acceso
- **Interfaz Web**: http://localhost:5000
- **API OpenStack**: http://localhost:5006
- **DocumentaciÃ³n API**: http://localhost:5006/api/docs

### Primer Uso
1. Acceder a http://localhost:5000
2. Registrarse como nuevo usuario
3. Verificar conectividad SSH en el dashboard
4. Subir primera imagen de VM
5. Crear primer slice con topologÃ­a predefinida

## TopologÃ­as Disponibles

### TopologÃ­a Lineal
```
â—‹ â”€â”€â”€ â—‹ â”€â”€â”€ â—‹ â”€â”€â”€ â—‹
A     B     C     D
```
- **Uso**: Pruebas de latencia, routing secuencial
- **Nodos**: 2-10
- **Conexiones**: Cada nodo conectado al siguiente

### TopologÃ­a Malla
```
â—‹ â†â†’ â—‹
â†•   â†•
â—‹ â†â†’ â—‹
```
- **Uso**: Alta disponibilidad, redundancia
- **Nodos**: 3-8
- **Conexiones**: Todos los nodos conectados entre sÃ­

### TopologÃ­a Ãrbol
```
      â—‹
    â•±   â•²
   â—‹     â—‹
  â•± â•²   â•± â•²
 â—‹   â—‹ â—‹   â—‹
```
- **Uso**: JerarquÃ­as, distribuciÃ³n de contenido
- **Nodos**: 3-15
- **Conexiones**: Estructura jerÃ¡rquica

### TopologÃ­a Anillo
```
â—‹ â”€â”€â”€ â—‹
â”‚     â”‚
â—‹ â”€â”€â”€ â—‹
```
- **Uso**: Redes token ring, redundancia circular
- **Nodos**: 3-12
- **Conexiones**: Cada nodo conectado a dos vecinos

### TopologÃ­a Bus
```
â—‹
â”‚
â—‹ â•â•â• â—‹ â•â•â• â—‹
â”‚
â—‹
```
- **Uso**: Redes compartidas, broadcast
- **Nodos**: 3-20
- **Conexiones**: Todos conectados a bus central

## API Endpoints

### AutenticaciÃ³n
- `POST /api/auth/login` - Login de usuario
- `POST /api/auth/register` - Registro de usuario
- `POST /api/auth/logout` - Logout

### Slices
- `GET /api/slices` - Listar slices del usuario
- `POST /api/slices` - Crear nuevo slice
- `GET /api/slices/{id}` - Obtener slice especÃ­fico
- `PUT /api/slices/{id}` - Actualizar slice
- `DELETE /api/slices/{id}` - Eliminar slice
- `POST /api/slices/{id}/deploy` - Desplegar slice

### ImÃ¡genes
- `GET /api/images` - Listar imÃ¡genes
- `POST /api/images` - Subir nueva imagen
- `DELETE /api/images/{id}` - Eliminar imagen

### Recursos
- `GET /api/resources/status` - Estado de recursos
- `GET /api/resources/metrics` - MÃ©tricas detalladas

### SSH Tunnels
- `GET /api/ssh-tunnel/status` - Estado de tÃºneles
- `POST /api/ssh-tunnel/start` - Iniciar tÃºneles
- `POST /api/ssh-tunnel/stop` - Detener tÃºneles
- `POST /api/ssh-tunnel/test` - Probar conexiÃ³n SSH

## ResoluciÃ³n de Problemas

### ConexiÃ³n SSH Falla
```bash
# Verificar conectividad al jumper
ping 10.20.12.187

# Probar SSH al jumper manualmente
ssh -p 5821 -v ubuntu@10.20.12.187

# Verificar clave SSH
ssh-add ~/.ssh/id_rsa

# Probar conectividad al headnode desde el jumper
ssh -p 5821 ubuntu@10.20.12.187 "ping -c 3 192.168.202.1"

# Verificar puertos OpenStack en el headnode
ssh -p 5821 ubuntu@10.20.12.187 "nc -z 192.168.202.1 5000"
```

### TÃºneles SSH No Se Establecen
1. Verificar que los puertos locales estÃ©n libres:
```bash
netstat -tlnp | grep 15000
```

2. Probar tÃºnel manual:
```bash
# Ejemplo: tÃºnel para Keystone
ssh -NL 15000:192.168.202.1:5000 ubuntu@10.20.12.187 -p 5821
```

3. Revisar logs del tunnel manager
4. Verificar configuraciÃ³n en `openstack_config_ssh.py`

### OpenStack No Responde
1. Verificar que el headnode OpenStack estÃ© corriendo:
```bash
ssh -p 5821 ubuntu@10.20.12.187 "systemctl status openstack"
```

2. Comprobar puertos OpenStack en el headnode:
```bash
ssh -p 5821 ubuntu@10.20.12.187 "ss -tlnp | grep :5000"
```

3. Verificar red interna entre jumper y headnode:
```bash
ssh -p 5821 ubuntu@10.20.12.187 "traceroute 192.168.202.1"
```

4. Revisar configuraciÃ³n de red/firewall en ambos servidores

### Errores de Base de Datos
```bash
# Recrear base de datos
rm *.db
python3 web_app.py  # Se crearÃ¡ automÃ¡ticamente
```

## Logs y Debugging

### UbicaciÃ³n de Logs
- **Web App**: stdout/stderr
- **OpenStack Service**: logs en consola
- **SSH Tunnels**: logs del sistema

### Modo Debug
```bash
# Activar debug en Flask
export FLASK_DEBUG=1
python3 web_app.py
```

### Verificar Estado de Servicios
```bash
# Procesos activos
ps aux | grep python

# Puertos en uso
netstat -tlnp | grep :500
```

## Arquitectura de Seguridad

### AutenticaciÃ³n
- JWT tokens con expiraciÃ³n
- Hashing seguro de contraseÃ±as
- ValidaciÃ³n de sesiones

### ComunicaciÃ³n
- HTTPS recomendado para producciÃ³n
- TÃºneles SSH encriptados
- ValidaciÃ³n de entrada en APIs

### Aislamiento
- Slices por usuario aislados
- Recursos limitados por usuario
- ValidaciÃ³n de permisos en todas las operaciones

## Desarrollo

### Estructura del Proyecto
```
cloud-2022/
â”œâ”€â”€ web_app.py              # AplicaciÃ³n web principal
â”œâ”€â”€ start_pucp_cloud.py     # Script de inicio
â”œâ”€â”€ templates/              # Templates HTML
â”œâ”€â”€ static/                 # CSS, JS, imÃ¡genes
â”œâ”€â”€ microservicios/         # Microservicios
â”‚   â”œâ”€â”€ openstack_service/  # Servicio OpenStack
â”‚   â”œâ”€â”€ ssh_tunnel_manager.py
â”‚   â””â”€â”€ edits/              # Configuraciones
â”œâ”€â”€ database/               # Esquemas BD
â””â”€â”€ conf/                   # Configuraciones
```

### Agregar Nueva TopologÃ­a
1. Editar `openstack_config_ssh.py`:
```python
PREDEFINED_TOPOLOGIES['nueva'] = {
    'name': 'Nueva TopologÃ­a',
    'description': 'DescripciÃ³n...',
    'template': {...}
}
```

2. Actualizar frontend en `slice-create.js`

### Contribuir
1. Fork del repositorio
2. Crear branch para feature
3. Agregar tests
4. Enviar pull request

## Licencia

Proyecto acadÃ©mico - PUCP 2025

## Soporte

Para problemas o preguntas:
- Revisar logs del sistema
- Verificar configuraciÃ³n SSH
- Comprobar conectividad de red
- Contactar al equipo de desarrollo